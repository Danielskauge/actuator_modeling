[34m[1mwandb[0m: logging graph, to disable use `wandb.watch(log_graph=False)`
GPU available: True (cuda), used: True
TPU available: False, using: 0 TPU cores
HPU available: False, using: 0 HPUs
Starting global training...
You are using a CUDA device ('NVIDIA GeForce RTX 3090') that has Tensor Cores. To properly utilize them, you should set `torch.set_float32_matmul_precision('medium' | 'high')` which will trade-off precision for performance. For more details, read https://pytorch.org/docs/stable/generated/torch.set_float32_matmul_precision.html#torch.set_float32_matmul_precision
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2]
Warning: Total training steps (inf) <= warmup steps (inf). Cosine decay might not behave as expected. Effective LR may be constant or only warmup.

  | Name          | Type       | Params | Mode
-----------------------------------------------------
0 | model         | GRUModel   | 150 K  | train
1 | train_metrics | ModuleDict | 0      | train
2 | val_metrics   | ModuleDict | 0      | train
3 | test_metrics  | ModuleDict | 0      | train
-----------------------------------------------------
150 K     Trainable params
0         Non-trainable params
150 K     Total params
0.601     Total estimated model params size (MB)
18        Modules in train mode
0         Modules in eval mode
Epoch 110: 100%|█| 132/132 [00:01<00:00, 74.41it/s, v_num=rpwn, train_loss_step=0.00567, val_loss=0.00403, val_mse_epoch=0.00332, val_rmse_epoch=0.0576, val_mae_epoch=0.0464, val_r2_epoch=0.827, train_loss_epoch=0.0041
Starting global testing...                                                                                                                                                                                                
Metric val_rmse_epoch improved. New best score: 0.092
/home/daniel/miniconda3/lib/python3.12/site-packages/pytorch_lightning/callbacks/lr_monitor.py:217: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
Metric val_rmse_epoch improved by 0.001 >= min_delta = 0.0001. New best score: 0.091
Metric val_rmse_epoch improved by 0.000 >= min_delta = 0.0001. New best score: 0.091
Metric val_rmse_epoch improved by 0.002 >= min_delta = 0.0001. New best score: 0.089
Metric val_rmse_epoch improved by 0.001 >= min_delta = 0.0001. New best score: 0.088
Metric val_rmse_epoch improved by 0.002 >= min_delta = 0.0001. New best score: 0.086
Metric val_rmse_epoch improved by 0.005 >= min_delta = 0.0001. New best score: 0.081
Metric val_rmse_epoch improved by 0.006 >= min_delta = 0.0001. New best score: 0.075
Metric val_rmse_epoch improved by 0.002 >= min_delta = 0.0001. New best score: 0.072
Metric val_rmse_epoch improved by 0.002 >= min_delta = 0.0001. New best score: 0.070
Metric val_rmse_epoch improved by 0.000 >= min_delta = 0.0001. New best score: 0.069
Metric val_rmse_epoch improved by 0.000 >= min_delta = 0.0001. New best score: 0.069
Metric val_rmse_epoch improved by 0.008 >= min_delta = 0.0001. New best score: 0.061
Metric val_rmse_epoch improved by 0.000 >= min_delta = 0.0001. New best score: 0.061
Metric val_rmse_epoch improved by 0.001 >= min_delta = 0.0001. New best score: 0.060
Metric val_rmse_epoch improved by 0.000 >= min_delta = 0.0001. New best score: 0.059
Metric val_rmse_epoch improved by 0.001 >= min_delta = 0.0001. New best score: 0.058
Metric val_rmse_epoch improved by 0.000 >= min_delta = 0.0001. New best score: 0.058
Metric val_rmse_epoch improved by 0.000 >= min_delta = 0.0001. New best score: 0.058
Metric val_rmse_epoch improved by 0.001 >= min_delta = 0.0001. New best score: 0.057
Metric val_rmse_epoch improved by 0.001 >= min_delta = 0.0001. New best score: 0.056
Metric val_rmse_epoch improved by 0.000 >= min_delta = 0.0001. New best score: 0.056
Metric val_rmse_epoch improved by 0.000 >= min_delta = 0.0001. New best score: 0.056
Metric val_rmse_epoch improved by 0.001 >= min_delta = 0.0001. New best score: 0.055
Monitored metric val_rmse_epoch did not improve in the last 20 records. Best score: 0.055. Signaling Trainer to stop.
Restoring states from the checkpoint path at /home/daniel/workspace/actuator_modeling/outputs/2025-05-28/14-48-57/checkpoints/global_run/gru-global_debug-epoch=90-val_rmse_epoch=0.0549.ckpt
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2]
Loaded model weights from the checkpoint at /home/daniel/workspace/actuator_modeling/outputs/2025-05-28/14-48-57/checkpoints/global_run/gru-global_debug-epoch=90-val_rmse_epoch=0.0549.ckpt
Testing DataLoader 0: 100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 29/29 [00:00<00:00, 256.44it/s]
Generating test set prediction plots...
Logging plots to WandB...
Plots logged.
Testing DataLoader 0: 100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 29/29 [00:00<00:00, 35.06it/s]
┏━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┓
┃[1m [0m[1m       Test metric       [0m[1m [0m┃[1m [0m[1m      DataLoader 0       [0m[1m [0m┃
┡━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━┩
│[36m [0m[36m        test_loss        [0m[36m [0m│[35m [0m[35m  0.004119606222957373   [0m[35m [0m│
│[36m [0m[36m     test_mae_epoch      [0m[36m [0m│[35m [0m[35m  0.046204812824726105   [0m[35m [0m│
│[36m [0m[36m     test_mse_epoch      [0m[36m [0m│[35m [0m[35m  0.0034554502926766872  [0m[35m [0m│
│[36m [0m[36m      test_r2_epoch      [0m[36m [0m│[35m [0m[35m   0.8235187530517578    [0m[35m [0m│
│[36m [0m[36m     test_rmse_epoch     [0m[36m [0m│[35m [0m[35m   0.05878307670354843   [0m[35m [0m│
└───────────────────────────┴───────────────────────────┘
Global Test Metrics: {'test_loss': 0.004119606222957373, 'test_mse_epoch': 0.0034554502926766872, 'test_rmse_epoch': 0.05878307670354843, 'test_mae_epoch': 0.046204812824726105, 'test_r2_epoch': 0.8235187530517578}
